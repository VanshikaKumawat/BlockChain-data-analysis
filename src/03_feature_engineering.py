# -*- coding: utf-8 -*-
"""03_feature_engineering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LNINhzfUzm7BdHC8i2rs8gH9ayHVSg0o
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import (
    classification_report, accuracy_score, confusion_matrix,
    roc_curve, auc
)
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv('/content/BlockChain-data-analysis/data/processed/cleaned_dataset.csv')


drop_cols = ['Unnamed: 0', 'Index']
df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)


df.columns = df.columns.str.strip()


X = df.drop(columns=['FLAG', 'Address'])
y = df['FLAG']

X.replace(' ', np.nan, inplace=True)
X = X.apply(pd.to_numeric, errors='coerce')
X.fillna(0, inplace=True)

scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)


X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

def plot_conf_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix: {model_name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

def plot_roc(y_true, y_score, model_name):
    fpr, tpr, _ = roc_curve(y_true, y_score)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.grid()
    plt.show()

def train_evaluate(model, name):
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None

    print(f"\nðŸ“Š Model: {name}")
    print("Accuracy:", accuracy_score(y_test, preds))
    print("Confusion Matrix:\n", confusion_matrix(y_test, preds))
    print("Classification Report:\n", classification_report(y_test, preds))


    plot_conf_matrix(y_test, preds, name)
    if proba is not None:
        plot_roc(y_test, proba, name)

train_evaluate(LogisticRegression(max_iter=1000), "Logistic Regression")

train_evaluate(RandomForestClassifier(n_estimators=100, random_state=42), "Random Forest")

train_evaluate(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42), "XGBoost")

summary_data = {
    "Model": ["Logistic Regression", "Random Forest", "XGBoost"],
    "Accuracy": [0.72, 0.986, 0.994],
    "Precision (Class 1)": [0.32, 1.00, 1.00],
    "Recall (Class 1)": [0.44, 0.93, 0.97],
    "F1-Score (Class 1)": [0.37, 0.96, 0.98]
}

summary_df = pd.DataFrame(summary_data)
print("\nFinal Model Comparison:\n")
print(summary_df.to_markdown(index=False))

print("XGBoost is best performer, with highest accuracy and F1-score, closely followed by Random Forest.")

